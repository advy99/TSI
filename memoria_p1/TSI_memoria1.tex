\documentclass[10pt, spanish]{article}
\usepackage[spanish]{babel}
\selectlanguage{spanish}
\usepackage{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{parskip}
\usepackage{fancyhdr}
\usepackage{vmargin}
\usepackage{multirow}
\usepackage{float}
\usepackage{chngpage}

\usepackage{subcaption}

\usepackage{hyperref}
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
]{doclicense}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% para codigo
\usepackage{listings}
\usepackage{xcolor}



%% configuración de listings

\definecolor{listing-background}{HTML}{F7F7F7}
\definecolor{listing-rule}{HTML}{B3B2B3}
\definecolor{listing-numbers}{HTML}{B3B2B3}
\definecolor{listing-text-color}{HTML}{000000}
\definecolor{listing-keyword}{HTML}{435489}
\definecolor{listing-identifier}{HTML}{435489}
\definecolor{listing-string}{HTML}{00999A}
\definecolor{listing-comment}{HTML}{8E8E8E}
\definecolor{listing-javadoc-comment}{HTML}{006CA9}

\lstdefinestyle{eisvogel_listing_style}{
  language         = c++,
%$if(listings-disable-line-numbers)$
%  xleftmargin      = 0.6em,
%  framexleftmargin = 0.4em,
%$else$
  numbers          = left,
  xleftmargin      = 0em,
 framexleftmargin = 0em,
%$endif$
  backgroundcolor  = \color{listing-background},
  basicstyle       = \color{listing-text-color}\small\ttfamily{}\linespread{1.15}, % print whole listing small
  breaklines       = true,
  frame            = single,
  framesep         = 0.19em,
  rulecolor        = \color{listing-rule},
  frameround       = ffff,
  tabsize          = 4,
  numberstyle      = \color{listing-numbers},
  aboveskip        = 1.0em,
  belowskip        = 0.1em,
  abovecaptionskip = 0em,
  belowcaptionskip = 1.0em,
  keywordstyle     = \color{listing-keyword}\bfseries,
  classoffset      = 0,
  sensitive        = true,
  identifierstyle  = \color{listing-identifier},
  commentstyle     = \color{listing-comment},
  morecomment      = [s][\color{listing-javadoc-comment}]{/**}{*/},
  stringstyle      = \color{listing-string},
  showstringspaces = false,
  escapeinside     = {/*@}{@*/}, % Allow LaTeX inside these special comments
  literate         =
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\'e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1 {«}{{\guillemotleft}}1
  {»}{{\guillemotright}}1 {ñ}{{\~n}}1 {Ñ}{{\~N}}1 {¿}{{?`}}1
  {…}{{\ldots}}1 {≥}{{>=}}1 {≤}{{<=}}1 {„}{{\glqq}}1 {“}{{\grqq}}1
  {”}{{''}}1
}
\lstset{style=eisvogel_listing_style}


\usepackage[default]{sourcesanspro}

\setmarginsrb{2 cm}{1 cm}{2 cm}{2 cm}{1 cm}{1.5 cm}{1 cm}{1.5 cm}

\title{Práctica 1:\\
Técnicas de Búsqueda Heurística  \hspace{0.05cm} }                           
\author{Antonio David Villegas Yeguas}                             
\date{\today}                                           

\renewcommand*\contentsname{hola}

\makeatletter
\let\thetitle\@title
\let\theauthor\@author
\let\thedate\@date
\makeatother

\pagestyle{fancy}
\fancyhf{}
\rhead{\theauthor}
\lhead{\thetitle}
\cfoot{\thepage}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{titlepage}
    \centering
    \vspace*{0.3 cm}
    \includegraphics[scale = 0.50]{ugr.png}\\[0.7 cm]
    %\textsc{\LARGE Universidad de Granada}\\[2.0 cm]   
    \textsc{\large 3º CSI 2019/20 - Grupo 1}\\[0.5 cm]            
    \textsc{\large Grado en Ingeniería Informática}\\[0.5 cm]              
    \rule{\linewidth}{0.2 mm} \\[0.2 cm]
    { \huge \bfseries \thetitle}\\
    \rule{\linewidth}{0.2 mm} \\[1 cm]
    
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
            \emph{Autor:}\\
            \theauthor\\ 
			 \emph{DNI:}\\
            77021623-M
            \end{flushleft}
            \end{minipage}~
            \begin{minipage}{0.4\textwidth}
            \begin{flushright} \large
            \emph{Asignatura: \\
            Técnicas de los Sistemas Inteligentes}   \\     
            \emph{Correo:}\\
            advy99@correo.ugr.es           
        \end{flushright}
    \end{minipage}\\[0.5cm]
  
    {\large \thedate}\\[0.5cm]
    %{\url{https://github.com/advy99/TSI/}}
    {\doclicenseThis}
 	
    \vfill
    
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\tableofcontents
%\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introducción}

Para esta práctica se nos pide desarrollar un agente que juegue al juego \"Boulder Dash\", videojuego de 1984 para las computadores Atari. Simularemos este juego a través del entorno de desarrollo GVGAI, desarrollado en Java. Este entorno de desarrollo se caracteriza por ser una IA que juega a juegos genéricos, donde el objetivo es conseguir ciertos materiales, y cuando se obtengan dichos materiales salir por una puerta, todo esto evitando enemigos (si los hubiera). El juego en el que nos centraremos, ``Boulderdash'', tiene el mismo objetivo aunque para el desarrollo de la práctica se nos plantean algunas variaciones que veremos más adelante.

El juego se desarrolla en un mapa cuadriculado para nuestro personaje (más adelante veremos que los enemigos tienen una forma distinta de moverse). Los movimientos que podrá realizar serán:

\begin{itemize}
	\item Moverse hacia arriba
	\item Moverse hacia abajo
	\item Moverse hacia la derecha
	\item Moverse hacia la izquierda
	\item No hacer nada
\end{itemize}

Además de esta acciones, si el personaje tiene que girarse, utilizará una acción para esto, es decir, si esta mirando hacia la derecha y quiere ir a la izquierda, necesitará dos ordenes de moverse a la izquierda, una para girarse y otra para realizar el movimiento.

Nuestro agente tendrá un segundo inicial para realizar cálculos a modo de preparación', tras eso, deberá responder con una de estas acciones en menos de 40ms, si tarda entre 40ms y 50ms automáticamente responderá con la acción de no hacer nada, y en caso de tardar más de 50ms el agente quedará descalificado y perderá.

El juego finaliza cuando se consigue el objetivo (en el caso del comportamiento deliberativo) o cuando el personaje sobrevive 2000 acciones (ticks dentro del juego, en el caso del comportamiento reactivo).

En este documento explicaré las consideraciones tomadas al desarrollar la práctica, y la forma en la que ha ido evolucionando el código desde el nivel 1 hasta el nivel 5.

\subsubsection{Consideraciones previas}

Para el desarrollo del agente suponemos que siempre hay un portal de salida en los mapas que requieran comportamiento deliberativo, además el portal escogido para salir ha de ser único y accesible. Si no es único (existe más de un portal), es seleccionado el más cercano al jugador en el momento de inicio del juego.

\section{Comportamiento deliberativo}

En el desarrollo de este apartado desarrollaremos el funcionamiento del agente deliberativo, es decir, el agente, con conocimiento del entorno, buscará la mejor forma de llegar al objetivo, en este nivel la puerta.

De cara a conseguir esto he decidido implementar el algoritmo de búsqueda de caminos A*, este algoritmo combina el algoritmo de Dijkstra con el algoritmo greedy Best-First, añadiendo el componente de heurística con el que guiaremos la búsqueda intentando avanzar hacia la solución, en lugar de explorar de forma uniforme el espacio de búsqueda.

Dicho esto, A* evaluará los nodos de la siguiente forma:

$$ f(n) = g(n) + h(h) $$

Donde $g(n)$ es el coste desde el punto de partida hasta el nodo $n$ y $h(n)$ es la heurística, es decir, la estimación que hacemos del coste desde el nodo $n$ hasta el nodo objetivo.

He escogido este algoritmo ya que cumple las dos restricciones básicas para que este funcione:

\begin{enumerate}
	\item El grafo es localmente finito: Para cada nodo el número de hijos es finito. Esto se cumple ya que cada nodo tendrá 4 hijos (cada una de las acciones, a excepción de quedarse quieto, ya que ese hijo es el propio nodo y no es necesario explorarlo).
	\item El coste de pasar de un nodo cualquiera a uno de sus sucesores es estrictamente positivo.
\end{enumerate}

No solo he escogido el algoritmo A* por estas características, que simplemente me permiten implementarlo en nuestro problema, si no porque como explicaré más adelante, para nuestro problema A* será un algoritmo completo, admisible, y con una heurística consistente (continua) lo que nos reducirá el coste computacional del algoritmo.

\subsubsection{Completitud de A*}

Para poder asegurar que A* es completo basta con demostrar que el grafo es finito, es decir, tiene un número finito de caminos acíclicos. En nuestro caso esto se cumple, ya que el número de casillas del mapa es finito, tendremos un número finito de caminos y podemos asegurar la completitud del algoritmo.

\subsubsection{Admisibilidad de A*}

En este caso la admisibilidad de A* depende de la heurística usada, ya que influirá en el orden de exploración de los nodos. Para que A* sea admisible, la heurística usada debe ser admisible, es decir, que se cumpla $h(n) \leq h^*(n)$. Básicamente que la estimación de nuestra heurística no sobreestime el coste real de llegar al nodo objetivo.

En esta práctica, al ser un mundo cuadriculado usaré como heurística la distancia Manhattan, en la que una casilla tendrá un coste de uno. Esta heurística es admisible ya que cualquier movimiento, como mínimo, tendrá coste uno, por lo que nuestra estimación será igual o menor al coste real, en el mejor de los casos (linea recta) $h(n) = h^*(n)$, y en caso de que tenga que hacer algún giro $h(n) = h^*(n) - num\_giros$, por lo que la heurística siempre es admisible, y en caso de encontrar algún obstáculo necesitará gastar más ticks para llegar al objetivo, luego será admisible en todos los casos.

\subsubsection{Heurística consistente (continua)}

A* usando distancia Manhattan como heurística tiene la ventaja de que es consistente, es decir, para cada nodo $n$ y cada sucesor $n'$ generado a parir de $n$ tras cualquier acción $a$, el coste estimado de alcanzar el objetivo desde $n$ es menor o igual que el coste de alcanzar $n'$ más el coste estimado de alcanzar el objetivo desde $n'$, es decir:

$$ h(n) \leq c(n, a, n') + h(n') $$

Esta desigualdad triangular, cumplida si usamos la distancia Manhattan, nos asegura que cuando el algoritmo explora (abre) un nodo, este va a ser el mejor camino encontrado para llegar a ese nodo, por lo que una vez que un nodo entra en cerrados, sabemos que ese es el mejor camino para ese nodo, haciendo que si encontramos otro camino a dicho nodo simplemente los desechamos porque esta propiedad nos asegura que va a ser un peor camino.


\subsubsection{Decisión de la elección del algoritmo}

Una vez explicado el funcionamiento de A*, en este apartado procederé a explicar porque finalmente he escogido dicho algoritmo frente a otros algoritmos de búsqueda de caminos. He decidido explicarlo en este orden para que se entiendan las propiedades por las que A* es una mejor opción.

\textbf{IDA*}:

A pesar de que el algoritmo IDA* puede parecer una buena idea, ya que seguimos manteniendo las propiedades antes comentadas por el A* con la ventaja de que no tenemos que almacenar información sobre los nodos frontera por explorar como en el algoritmo escogido, si no que solo almacena información sobre el camino actual, la forma de conseguir esta mejora en memoria hace que el algoritmo no sea viable en tiempo, ya que ha de ir explorando rama a rama todos los posibles caminos.

Al tener tan solo 40ms para realizar los distintos cálculos, sumado a que en nuestro caso no existirá el problema de memoria al ser mapas pequeños y ahorrarnos la reexploración al usar una heurística consistente he decidido no usar este algoritmo ya que la única ventaja que nos ofrece no es realmente necesaria, sumado a la perdida de tiempo de computo y posiblemente la descalificación por no encontrar solución a tiempo.

\textbf{Algoritmo de Dijkstra}:

Este algoritmo proporciona el camino más corto entre un nodo y todos los demás, por lo que no es factible para grafos grandes, además, este algoritmo no usa búsqueda heurística, sumado a que el algoritmo A* es una variación de este algoritmo, que mejora la búsqueda al hacer uso de la heurística, escogería este algoritmo si no existiera heurística que me garantice que A* es admisible, pero como hemos comentado antes, existe y además mejora el algoritmo al ser consistente.

\textbf{Algoritmo Greedy Best-First Search}:

Este algoritmo usa únicamente la información heurística, por lo que busca el camino más directo al destino, pero sin tener en cuenta lo ya recorrido, por lo que un camino que parecía una buena opción al puede ser un mal camino al no tener en cuenta el coste hasta ese momento.

De nuevo, el algoritmo escogido es una combinación de este algoritmo Greedy y el algoritmo del apartado anterior, de forma que tenga en cuenta la estimación del camino, pero siendo consciente de lo que ya lleva recorrido, y cambiando de camino si es necesario.


\textbf{Otros algoritmos}:

También he tenido en cuenta otros algoritmos, como el algoritmo de búsqueda por franjas o el algoritmo Theta* visto en teoría, sin embargo me he encontrado que son modificaciones de IDA* o A* para casos concretos en los que A* no se comporta bien, sin embargo en nuestro problema no es el caso, así que he decidido no implementarlos.

\subsection{Deliberativo simple}

De cara al desarrollo del agente deliberativo simple he hecho uso del algoritmo A* con heurística distancia Manhattan como antes he comentado. En este nivel nuestro agente simplemente intenta encontrar la puerta y salir.

\subsubsection{Implementación del algoritmo A*}

Para implementar el algoritmo A* he usado la clase \texttt{Node} disponible en el paquete \texttt{pathfinder} de GVGAI, aunque realizando algunas modificaciones:

\begin{enumerate}
	\item Añadido variable para la orientación, la cual tenemos en cuenta para comprobar si dos nodos son iguales.
	\item Modificación del método \texttt{getMov} para que en lugar de no devolver nada (el uso era interno) devuelva la acción que ha conseguido llegar a ese estado.
\end{enumerate}

El primer punto es bastante importante, ya que si no sería mucho más difícil tener en cuenta la orientación al generar los nodos hijos, como veremos más adelante, lo que nos llevaría a un calculo erróneo de $g(n)$. Con respecto a la representación, he usado la siguiente:

\begin{enumerate}
	\item 0: Mirando hacia arriba
	\item 1: Mirando hacia la derecha
	\item 2: Mirando hacia abajo
	\item 3: Mirando hacia la izquierda
\end{enumerate}

También he implementado una función para pasar de la representación de orientación dada por GVGAI a la mía, disponible en el código fuente que acompaña esta memoria.

El segundo punto es importante ya que usaremos ese método para obtener la lista de movimientos una vez tengamos la solución.

Dicho esto, la implementación del algoritmo sería la siguiente:

\begin{lstlisting}
Nodo algoritmoA-estrella( inicio, destino)
	ColaPrioridad abiertos
	ColaPrioridad cerrados
	abiertos.add(inicio)
	es_solucion = false
	acciones = {UP, DOWN, LEFT, RIGTH}
	Mientras !es_solucion
		mejor_abiertos = abiertos.sacar_tope
		cerrados.add(mejor_abiertos)
		es_solucion = mejor_abiertos.equals(destino)
		Si !es_solucion
			Para cada accion en acciones:
				Nodo hijo = mejor_abiertos
				Muevo hijo.position acorde a accion, actualizo orientación
				Si !esObstaculo(hijo)
					hijo.parent = mejor_abiertos
					hijo.coste = mejor_abiertos.coste + 1
					hijo.costeEstimado = distancia_manhattan(hijo, fin)
					Si hijo.orientacion != mejor_abiertos.orientacion
						hijo.coste++
					Si !abiertos.contiene(hijo) Y !cerrados.contiene(hijo)
						abiertos.add(hijo)
					Si No
						Si abiertos.contiene(hijo)
							buscar el nodo en abiertos, si el nuevo hijo es mejor, lo actualizamos
	Devolver mejor_abiertos
\end{lstlisting}

Una vez tenemos el nodo \texttt{mejor\_abiertos} simplemente lo recorremos hasta que su padre sea nulo, metiendo las acciones recogidas con el método \texttt{getMov}, en caso de que sea la acción nula duplicamos la acción del tope de la pila, ya que la acción nula equivale a quedarse en la misma casilla, lo que indica que estamos girando.

\subsubsection{Cambios necesarios en el método act y constructor del agente}

Los cambios que he tenido que realizar en el constructor son crear una variable de tipo Pila que almacenará los pasos necesarios para llegar al destino. He escogido este tipo de estructura de datos ya que siempre accederemos al elemento superior, y aunque a primera vista de la impresión de que estamos accediendo en orden inverso a los elementos, nuestro A* nos devolverá el nodo solución, y para obtener el camino iremos desde dicho nodo hacia el inicial a través del atributo \texttt{parent} de los distintos nodos, por lo que estamos leyendo en orden inverso el camino. Al almacenarlo en una pila, lo almacenamos en orden inverso al leído, es decir, el orden correcto.

Los cambios necesarios en el método \texttt{act} han sido añadir una condición, si el plan esta vacío, lanzamos el algoritmo A* y calculamos el plan a partir del nodo devuelto. En este caso suponemos que siempre existe el camino, es decir, que siempre hay portal (condición necesaria de la práctica). Si el plan no está vacío simplemente sacamos acciones del plan y las devolvemos.

Como hemos comprobado en la explicación del algoritmo, tenemos un algoritmo completo, admisible, consistente y además con unos tiempos de ejecución muy buenos.

Esta implementación nos hace obtener 27 ticks en el mapa 5.

\newpage

\subsection{Deliberativo compuesto}

En este nivel, además de alcanzar la salida, el objetivo será conseguir 10 gemas distribuidas por el mapa. Para conseguir esto simplemente pruebo los distintos caminos posibles entre las gemas, es decir, suponiendo que tenemos 3 gemas A, B y C probaremos con los caminos: \{A, B, C\}, escogeremos el de menor distancia y generamos sus hijos, por ejemplo, suponiendo que B tiene menor distancia tendríamos: \{A, C, BA, BC\}, y volveríamos a coger el de menor distancia, hasta que lleguemos al objetivo, coger las 10 gemas, cuando lleguemos obtener todas y saquemos ese camino, por ejemplo el \{BAC\}, todavía tenemos que introducir en la lista de caminos el \{BACP\}, para comprobar que con la vuelta al portal es el mejor camino. Para realizar la implementación tenemos que tener algunas cosas más en cuenta.

Para empezar, el coste de realizar este calculo es exponencial, en el ejemplo anterior, con 3 gemas, tenemos 3! + 3! posibles caminos (3! por las combinaciones A, B y C y otro 3! por dichas combinaciones sumarles el portal para llegar a la salida).

Para seleccionar los nodos uso la estrategia del algoritmo de Dijkstra, el que tenga menor coste. El coste será la distancia entre las distintas gemas, el inicio, en nuestro ejemplo \{A, B, C\}, cada gema tendrá asociada el coste de ir desde la posición del jugador hasta A, hasta B o hasta C respectivamente. Para calcular estas distancias usaremos el algoritmo A*, ya que sabemos que con el obtenemos el optimo. Al principio del calculo relleno la parte superior de una matriz con tantas filas y columnas como número de gemas más dos (este último más dos para la distancia del punto inicial a las gemas y la distancia de las gemas al portal).

He pensado en como mejorar este algoritmo, pero tras darle muchas vueltas no se me ocurre ninguna heurística que funcione a la hora de escoger que camino puede ser mejor que otro, ya que todas las que he probado (distancia entre una secuencia aleatoria de entre las gemas restantes, distancia de la última gema al portal multiplicado por el número de gemas restantes, distancia más grande de la matriz por número restante de gemas, entre otras) me daban peores resultados que un greedy simple, por lo que simplemente he dejado el algoritmo de esta forma, ya que con el segundo del constructor es capaz de calcularlo en todos los mapas que he probado, pero con una condición. Esta condición es que tenga menos de 12 gemas, si el mapa tiene 15, el límite superior con el que se corrige, tarda demasiado.

Esto lo he solucionado cortando el vector de gemas a doce, con las doce más cercanas al jugador (usando el método \texttt{getResourcePositions()}), ya que podemos suponer que esas gemas son las más prometedoras.

Con esto nos aseguramos obtener buenos resultados, que aunque no sean el óptimo, estarán muy cerca, porque será el óptimo de entre esas 12 gemas. En caso de que el mapa tenga menos de 12 gemas, obtendremos el óptimo, como por ejemplo en el mapa 6, que obtenemos 84 ticks.

\section{Comportamiento reactivo}

El comportamiento reactivo se basa en evitar los enemigos que encontramos por el mapa. Para el desarrollo de este comportamiento tendré un mapa de calor, que me indicará las zonas peligrosas del juego. En este caso el agente actuará de la forma más simple posible: moverse a la casilla de menor riesgo inmediata al personaje. He decidido seguir la navaja de Ockham, la forma más simple suele ser la más probable, en este caso, la forma que mejor funcione, he decidido esto tras varios intentos de buscar la mejor forma de moverse por el mapa, sin conseguir claramente un vencedor, a excepción del método, que con un mapa de calor detallado y preciso se comporta muy bien (con las pruebas realizadas siempre sobrevive el agente, a excepción de casos extremos como pasillos).

\subsection{Reactivo simple}

De cara a implementar el agente reactivo simple he diseñado una matriz a modo de mapa de calor. Tendremos dos matrices: \texttt{mapa\_base} y \texttt{mapa\_calor}. El mapa base lo calcularemos únicamente una vez en el constructor del agente, y contendrá información del peligro de objetos fijos (muros), que nunca cambiarán durante la ejecución. El mapa de calor contendrá el mapa de calor durante esa iteración, y será el que calcularemos cada vez que se ejecuta el método \texttt{act}.

\subsection{Reactivo compuesto}

\section{Comportamiento reactivo-deliverativo}


\end{document}
